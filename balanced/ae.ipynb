{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars_raiz = pl.read_parquet('../dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars_raiz.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "def ip_to_int(ip: str) -> int:\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))  # Funciona tanto para IPv4 quanto IPv6\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars = df_polars.with_columns([\n",
    "#    pl.col('id.resp_h').map_elements(ip_to_int).alias('id.resp_h'),\n",
    "#    pl.col('id.orig_h').map_elements(ip_to_int).alias('id.orig_h')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns([\n",
    "    pl.col('duration').fill_null(0),\n",
    "    pl.col('orig_bytes').fill_null(0),\n",
    "    pl.col('resp_bytes').fill_null(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas = df_polars.columns\n",
    "colunas_para_spearman = ['id.resp_p', 'history', 'conn_state', 'id.orig_p', 'orig_ip_bytes', 'label']             \n",
    "#['detailed-label', 'id.resp_p', 'history', 'id.orig_h', 'conn_state', 'id.orig_p', 'orig_ip_bytes']\n",
    "colunas_para_dropar = [col for col in lista_colunas if col not in colunas_para_spearman]\n",
    "df_polars = df_polars.drop(colunas_para_dropar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_polars.drop('label')\n",
    "y = df_polars['label']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.to_numpy()\n",
    "#X[:, 0] = np.array([ip_to_int(ip) for ip in X[:, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 8),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrain(X, y, hidden_dim=8, epochs=10, learning_rate=0.001, batch_size = 5000):\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    results_fold = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(X)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Aplicar MinMaxScaler APENAS aos dados de treino\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "\n",
    "        rus = RandomUnderSampler()\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "        # Filtrar apenas os dados benignos (classe 0) para treinar o Autoencoder\n",
    "        X_train_resampled = X_train_resampled[y_train_resampled == 0]\n",
    "        \n",
    "        # Converter para tensores PyTorch\n",
    "        X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        # Criar DataLoaders\n",
    "        batch_size = batch_size\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Configuração do dispositivo e modelo\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        input_dim = X_train.shape[1]\n",
    "        model = Autoencoder(input_dim=input_dim, hidden_dim=hidden_dim).to(device)\n",
    "\n",
    "        # Definição da função de perda e otimizador\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Treinamento\n",
    "        start_training = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for data in train_loader:\n",
    "                inputs = data[0].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        end_training = time.time()\n",
    "\n",
    "        # Avaliação do limiar baseado no conjunto de treino\n",
    "        model.eval()\n",
    "        reconstruction_errors_train = []\n",
    "        with torch.no_grad():\n",
    "            for data in train_loader:\n",
    "                inputs = data[0].to(device)\n",
    "                outputs = model(inputs)\n",
    "                reconstruction_error = torch.mean((outputs - inputs) ** 2, dim=1)\n",
    "                reconstruction_errors_train.extend(reconstruction_error.cpu().numpy())\n",
    "\n",
    "        reconstruction_errors_train = np.array(reconstruction_errors_train)\n",
    "        threshold = np.percentile(reconstruction_errors_train, 95)  # Limiar baseado no percentil 95\n",
    "\n",
    "        # Avaliação no conjunto de teste\n",
    "        reconstruction_errors_test = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                inputs, targets = data[0].to(device), data[1].cpu().numpy()\n",
    "                outputs = model(inputs)\n",
    "                reconstruction_error = torch.mean((outputs - inputs) ** 2, dim=1).cpu().numpy()\n",
    "                reconstruction_errors_test.extend(reconstruction_error)\n",
    "                y_pred.extend((reconstruction_error > threshold).astype(int))\n",
    "\n",
    "        # Conversão para numpy arrays\n",
    "        reconstruction_errors_test = np.array(reconstruction_errors_test)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Cálculo de métricas de desempenho\n",
    "        evaluation_time = time.time()\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "        training_duration = end_training - start_training\n",
    "        evaluation_duration = time.time() - end_training\n",
    "        avaliacao = [accuracy, balanced_accuracy, precision, recall, specificity, f1, false_alarm_rate, tn, fp, fn, tp, training_duration, evaluation_duration]\n",
    "        #print(avaliacao)\n",
    "        results_fold.append(avaliacao)\n",
    "\n",
    "    results_fold_array = np.array(results_fold, dtype=np.float32)\n",
    "    mean_results = np.mean(results_fold_array, axis=0)\n",
    "    results.append([\"AE\"] + mean_results.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melhores Hiperparâmetros encontrados: {'hidden_dim': 16, 'epochs': 20, 'learning_rate': 0.001, 'batch_size': 512}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    startTrain(X, y, hidden_dim=16, epochs=20, learning_rate=0.001, batch_size=512)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Algorithm</th><th>Accuracy</th><th>Balanced Accuracy</th><th>Precision</th><th>Recall</th><th>Specificity</th><th>F1-score</th><th>False Alarm Rate</th><th>tn</th><th>fp</th><th>fn</th><th>tp</th><th>training_duration</th><th>evaluation_duration</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;AE&quot;</td><td>0.982494</td><td>0.969312</td><td>0.990418</td><td>0.988711</td><td>0.949913</td><td>0.989563</td><td>0.050087</td><td>16911.400391</td><td>891.799988</td><td>1052.199951</td><td>92191.203125</td><td>10.481748</td><td>1.326094</td></tr><tr><td>&quot;AE&quot;</td><td>0.983421</td><td>0.969866</td><td>0.990429</td><td>0.98982</td><td>0.949913</td><td>0.990124</td><td>0.050087</td><td>16911.400391</td><td>891.799988</td><td>949.200012</td><td>92294.203125</td><td>10.195984</td><td>1.42185</td></tr><tr><td>&quot;AE&quot;</td><td>0.972992</td><td>0.963733</td><td>0.990343</td><td>0.977378</td><td>0.950089</td><td>0.983682</td><td>0.049911</td><td>16914.599609</td><td>888.599976</td><td>2110.600098</td><td>91132.796875</td><td>10.615119</td><td>1.575993</td></tr><tr><td>&quot;AE&quot;</td><td>0.983785</td><td>0.970034</td><td>0.990413</td><td>0.990275</td><td>0.949794</td><td>0.990344</td><td>0.050206</td><td>16909.400391</td><td>893.799988</td><td>906.799988</td><td>92336.601562</td><td>20.070271</td><td>2.266959</td></tr><tr><td>&quot;AE&quot;</td><td>0.981773</td><td>0.968938</td><td>0.990436</td><td>0.987832</td><td>0.950044</td><td>0.989131</td><td>0.049956</td><td>16913.800781</td><td>889.400024</td><td>1134.599976</td><td>92108.796875</td><td>12.899594</td><td>1.613766</td></tr><tr><td>&quot;AE&quot;</td><td>0.982906</td><td>0.969567</td><td>0.990428</td><td>0.989201</td><td>0.949933</td><td>0.989814</td><td>0.050067</td><td>16911.800781</td><td>891.400024</td><td>1006.799988</td><td>92236.601562</td><td>10.798182</td><td>1.380664</td></tr><tr><td>&quot;AE&quot;</td><td>0.982146</td><td>0.969223</td><td>0.990472</td><td>0.988244</td><td>0.950201</td><td>0.989356</td><td>0.049799</td><td>16916.800781</td><td>886.400024</td><td>1096.199951</td><td>92147.203125</td><td>9.89394</td><td>1.347006</td></tr><tr><td>&quot;AE&quot;</td><td>0.983126</td><td>0.96976</td><td>0.99046</td><td>0.989434</td><td>0.950087</td><td>0.989946</td><td>0.049913</td><td>16914.599609</td><td>888.599976</td><td>985.200012</td><td>92258.203125</td><td>9.879184</td><td>1.302922</td></tr><tr><td>&quot;AE&quot;</td><td>0.983645</td><td>0.969939</td><td>0.990405</td><td>0.990114</td><td>0.949764</td><td>0.990259</td><td>0.050236</td><td>16908.800781</td><td>894.400024</td><td>921.799988</td><td>92321.601562</td><td>10.388388</td><td>1.374155</td></tr><tr><td>&quot;AE&quot;</td><td>0.983373</td><td>0.969791</td><td>0.990408</td><td>0.989784</td><td>0.949799</td><td>0.990096</td><td>0.050201</td><td>16909.400391</td><td>893.799988</td><td>952.599976</td><td>92290.796875</td><td>10.50289</td><td>1.42697</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 14)\n",
       "┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Algorithm ┆ Accuracy ┆ Balanced  ┆ Precision ┆ … ┆ fn        ┆ tp        ┆ training_ ┆ evaluatio │\n",
       "│ ---       ┆ ---      ┆ Accuracy  ┆ ---       ┆   ┆ ---       ┆ ---       ┆ duration  ┆ n_duratio │\n",
       "│ str       ┆ f64      ┆ ---       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ ---       ┆ n         │\n",
       "│           ┆          ┆ f64       ┆           ┆   ┆           ┆           ┆ f64       ┆ ---       │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64       │\n",
       "╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ AE        ┆ 0.982494 ┆ 0.969312  ┆ 0.990418  ┆ … ┆ 1052.1999 ┆ 92191.203 ┆ 10.481748 ┆ 1.326094  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 51        ┆ 125       ┆           ┆           │\n",
       "│ AE        ┆ 0.983421 ┆ 0.969866  ┆ 0.990429  ┆ … ┆ 949.20001 ┆ 92294.203 ┆ 10.195984 ┆ 1.42185   │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 2         ┆ 125       ┆           ┆           │\n",
       "│ AE        ┆ 0.972992 ┆ 0.963733  ┆ 0.990343  ┆ … ┆ 2110.6000 ┆ 91132.796 ┆ 10.615119 ┆ 1.575993  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 98        ┆ 875       ┆           ┆           │\n",
       "│ AE        ┆ 0.983785 ┆ 0.970034  ┆ 0.990413  ┆ … ┆ 906.79998 ┆ 92336.601 ┆ 20.070271 ┆ 2.266959  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 8         ┆ 562       ┆           ┆           │\n",
       "│ AE        ┆ 0.981773 ┆ 0.968938  ┆ 0.990436  ┆ … ┆ 1134.5999 ┆ 92108.796 ┆ 12.899594 ┆ 1.613766  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 76        ┆ 875       ┆           ┆           │\n",
       "│ AE        ┆ 0.982906 ┆ 0.969567  ┆ 0.990428  ┆ … ┆ 1006.7999 ┆ 92236.601 ┆ 10.798182 ┆ 1.380664  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 88        ┆ 562       ┆           ┆           │\n",
       "│ AE        ┆ 0.982146 ┆ 0.969223  ┆ 0.990472  ┆ … ┆ 1096.1999 ┆ 92147.203 ┆ 9.89394   ┆ 1.347006  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 51        ┆ 125       ┆           ┆           │\n",
       "│ AE        ┆ 0.983126 ┆ 0.96976   ┆ 0.99046   ┆ … ┆ 985.20001 ┆ 92258.203 ┆ 9.879184  ┆ 1.302922  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 2         ┆ 125       ┆           ┆           │\n",
       "│ AE        ┆ 0.983645 ┆ 0.969939  ┆ 0.990405  ┆ … ┆ 921.79998 ┆ 92321.601 ┆ 10.388388 ┆ 1.374155  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 8         ┆ 562       ┆           ┆           │\n",
       "│ AE        ┆ 0.983373 ┆ 0.969791  ┆ 0.990408  ┆ … ┆ 952.59997 ┆ 92290.796 ┆ 10.50289  ┆ 1.42697   │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 6         ┆ 875       ┆           ┆           │\n",
       "└───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pl.DataFrame(\n",
    "    results,\n",
    "    schema=['Algorithm', 'Accuracy', 'Balanced Accuracy' , 'Precision', 'Recall', 'Specificity', 'F1-score', 'False Alarm Rate', 'tn', 'fp', 'fn', 'tp', 'training_duration', 'evaluation_duration']\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.write_csv(f\"metrics_results/balanced_AE_metrics_output.csv\", separator=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_2025_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
