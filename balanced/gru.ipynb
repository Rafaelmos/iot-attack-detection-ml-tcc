{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "import ipaddress\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars_raiz = pl.read_parquet('../dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars_raiz.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_to_int(ip: str) -> int:\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))  # Funciona tanto para IPv4 quanto IPv6\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars = df_polars.with_columns([\n",
    "#    pl.col('id.resp_h').map_elements(ip_to_int).alias('id.resp_h'),\n",
    "#    pl.col('id.orig_h').map_elements(ip_to_int).alias('id.orig_h')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns([\n",
    "    pl.col('duration').fill_null(0),\n",
    "    pl.col('orig_bytes').fill_null(0),\n",
    "    pl.col('resp_bytes').fill_null(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas = df_polars.columns\n",
    "colunas_para_manter = ['ts', 'id.resp_p', 'history', 'conn_state', 'id.orig_p', 'orig_ip_bytes', 'label']  \n",
    "colunas_para_dropar = [col for col in lista_colunas if col not in colunas_para_manter]\n",
    "df_polars = df_polars.drop(colunas_para_dropar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.drop_nulls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (555_233, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>id.orig_p</th><th>id.resp_p</th><th>conn_state</th><th>history</th><th>orig_ip_bytes</th><th>label</th></tr><tr><td>f64</td><td>i32</td><td>i32</td><td>i64</td><td>i64</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>1.5322e9</td><td>5526</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>1.5326e9</td><td>60403</td><td>23</td><td>2</td><td>7</td><td>40</td><td>1</td></tr><tr><td>1.5326e9</td><td>13386</td><td>81</td><td>2</td><td>7</td><td>40</td><td>1</td></tr><tr><td>1.5455e9</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>1.5454e9</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1.5514e9</td><td>30535</td><td>8081</td><td>1</td><td>1</td><td>80</td><td>1</td></tr><tr><td>1.5454e9</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>1.5514e9</td><td>41258</td><td>23</td><td>1</td><td>1</td><td>120</td><td>1</td></tr><tr><td>1.5514e9</td><td>36658</td><td>23</td><td>1</td><td>1</td><td>120</td><td>1</td></tr><tr><td>1.5454e9</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (555_233, 7)\n",
       "┌──────────┬───────────┬───────────┬────────────┬─────────┬───────────────┬───────┐\n",
       "│ ts       ┆ id.orig_p ┆ id.resp_p ┆ conn_state ┆ history ┆ orig_ip_bytes ┆ label │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---        ┆ ---     ┆ ---           ┆ ---   │\n",
       "│ f64      ┆ i32       ┆ i32       ┆ i64        ┆ i64     ┆ i64           ┆ i32   │\n",
       "╞══════════╪═══════════╪═══════════╪════════════╪═════════╪═══════════════╪═══════╡\n",
       "│ 1.5322e9 ┆ 5526      ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ 1.5326e9 ┆ 60403     ┆ 23        ┆ 2          ┆ 7       ┆ 40            ┆ 1     │\n",
       "│ 1.5326e9 ┆ 13386     ┆ 81        ┆ 2          ┆ 7       ┆ 40            ┆ 1     │\n",
       "│ 1.5455e9 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ 1.5454e9 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ …        ┆ …         ┆ …         ┆ …          ┆ …       ┆ …             ┆ …     │\n",
       "│ 1.5514e9 ┆ 30535     ┆ 8081      ┆ 1          ┆ 1       ┆ 80            ┆ 1     │\n",
       "│ 1.5454e9 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ 1.5514e9 ┆ 41258     ┆ 23        ┆ 1          ┆ 1       ┆ 120           ┆ 1     │\n",
       "│ 1.5514e9 ┆ 36658     ┆ 23        ┆ 1          ┆ 1       ┆ 120           ┆ 1     │\n",
       "│ 1.5454e9 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "└──────────┴───────────┴───────────┴────────────┴─────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns(pl.col(\"ts\").cast(pl.Int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (555_233, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>id.orig_p</th><th>id.resp_p</th><th>conn_state</th><th>history</th><th>orig_ip_bytes</th><th>label</th></tr><tr><td>i64</td><td>i32</td><td>i32</td><td>i64</td><td>i64</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>1532150893</td><td>5526</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>1532570324</td><td>60403</td><td>23</td><td>2</td><td>7</td><td>40</td><td>1</td></tr><tr><td>1532564882</td><td>13386</td><td>81</td><td>2</td><td>7</td><td>40</td><td>1</td></tr><tr><td>1545465243</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>1545398682</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1551404209</td><td>30535</td><td>8081</td><td>1</td><td>1</td><td>80</td><td>1</td></tr><tr><td>1545414126</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr><tr><td>1551402739</td><td>41258</td><td>23</td><td>1</td><td>1</td><td>120</td><td>1</td></tr><tr><td>1551405886</td><td>36658</td><td>23</td><td>1</td><td>1</td><td>120</td><td>1</td></tr><tr><td>1545405686</td><td>36097</td><td>37215</td><td>0</td><td>0</td><td>40</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (555_233, 7)\n",
       "┌────────────┬───────────┬───────────┬────────────┬─────────┬───────────────┬───────┐\n",
       "│ ts         ┆ id.orig_p ┆ id.resp_p ┆ conn_state ┆ history ┆ orig_ip_bytes ┆ label │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---        ┆ ---     ┆ ---           ┆ ---   │\n",
       "│ i64        ┆ i32       ┆ i32       ┆ i64        ┆ i64     ┆ i64           ┆ i32   │\n",
       "╞════════════╪═══════════╪═══════════╪════════════╪═════════╪═══════════════╪═══════╡\n",
       "│ 1532150893 ┆ 5526      ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ 1532570324 ┆ 60403     ┆ 23        ┆ 2          ┆ 7       ┆ 40            ┆ 1     │\n",
       "│ 1532564882 ┆ 13386     ┆ 81        ┆ 2          ┆ 7       ┆ 40            ┆ 1     │\n",
       "│ 1545465243 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ 1545398682 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ …          ┆ …         ┆ …         ┆ …          ┆ …       ┆ …             ┆ …     │\n",
       "│ 1551404209 ┆ 30535     ┆ 8081      ┆ 1          ┆ 1       ┆ 80            ┆ 1     │\n",
       "│ 1545414126 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "│ 1551402739 ┆ 41258     ┆ 23        ┆ 1          ┆ 1       ┆ 120           ┆ 1     │\n",
       "│ 1551405886 ┆ 36658     ┆ 23        ┆ 1          ┆ 1       ┆ 120           ┆ 1     │\n",
       "│ 1545405686 ┆ 36097     ┆ 37215     ┆ 0          ┆ 0       ┆ 40            ┆ 1     │\n",
       "└────────────┴───────────┴───────────┴────────────┴─────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar apenas pelo campo de tempo \"ts\"\n",
    "df_polars = df_polars.sort(\"ts\")\n",
    "\n",
    "window_size = 5  # Tamanho da janela temporal\n",
    "step_size = 1  # Passo entre janelas\n",
    "\n",
    "def create_sequences(df, window_size, step_size):\n",
    "    sequences, labels = [], []\n",
    "    \n",
    "    # Remover a coluna \"ts\" antes de converter para numpy\n",
    "    group_np = df.drop(\"ts\").to_numpy()\n",
    "    \n",
    "    for i in range(0, len(group_np) - window_size, step_size):\n",
    "        seq = group_np[i:i + window_size, :-1]  # Características\n",
    "        label = group_np[i + window_size - 1, -1]  # Última linha como rótulo\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "\n",
    "# Gerando X e y\n",
    "X, y = create_sequences(df_polars, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (555228, 5, 5)\n",
      "Shape de y: (555228,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape de X:\", X.shape)\n",
    "print(\"Shape de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (555_233, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>id.orig_p</th><th>id.resp_p</th><th>conn_state</th><th>history</th><th>orig_ip_bytes</th><th>label</th></tr><tr><td>i64</td><td>i32</td><td>i32</td><td>i64</td><td>i64</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>1525879873</td><td>37334</td><td>23</td><td>0</td><td>0</td><td>180</td><td>1</td></tr><tr><td>1525879921</td><td>40983</td><td>56742</td><td>0</td><td>0</td><td>180</td><td>0</td></tr><tr><td>1525879944</td><td>46566</td><td>8080</td><td>0</td><td>0</td><td>60</td><td>1</td></tr><tr><td>1525879960</td><td>36497</td><td>8080</td><td>0</td><td>0</td><td>60</td><td>1</td></tr><tr><td>1525880010</td><td>40761</td><td>2323</td><td>0</td><td>0</td><td>60</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1569018535</td><td>56399</td><td>62336</td><td>4</td><td>7</td><td>0</td><td>1</td></tr><tr><td>1569018535</td><td>44790</td><td>62336</td><td>4</td><td>7</td><td>0</td><td>1</td></tr><tr><td>1569018535</td><td>9799</td><td>62336</td><td>4</td><td>7</td><td>0</td><td>1</td></tr><tr><td>1569018535</td><td>16739</td><td>62336</td><td>4</td><td>7</td><td>0</td><td>1</td></tr><tr><td>1569024094</td><td>39645</td><td>80</td><td>2</td><td>5</td><td>15036790</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (555_233, 7)\n",
       "┌────────────┬───────────┬───────────┬────────────┬─────────┬───────────────┬───────┐\n",
       "│ ts         ┆ id.orig_p ┆ id.resp_p ┆ conn_state ┆ history ┆ orig_ip_bytes ┆ label │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---        ┆ ---     ┆ ---           ┆ ---   │\n",
       "│ i64        ┆ i32       ┆ i32       ┆ i64        ┆ i64     ┆ i64           ┆ i32   │\n",
       "╞════════════╪═══════════╪═══════════╪════════════╪═════════╪═══════════════╪═══════╡\n",
       "│ 1525879873 ┆ 37334     ┆ 23        ┆ 0          ┆ 0       ┆ 180           ┆ 1     │\n",
       "│ 1525879921 ┆ 40983     ┆ 56742     ┆ 0          ┆ 0       ┆ 180           ┆ 0     │\n",
       "│ 1525879944 ┆ 46566     ┆ 8080      ┆ 0          ┆ 0       ┆ 60            ┆ 1     │\n",
       "│ 1525879960 ┆ 36497     ┆ 8080      ┆ 0          ┆ 0       ┆ 60            ┆ 1     │\n",
       "│ 1525880010 ┆ 40761     ┆ 2323      ┆ 0          ┆ 0       ┆ 60            ┆ 1     │\n",
       "│ …          ┆ …         ┆ …         ┆ …          ┆ …       ┆ …             ┆ …     │\n",
       "│ 1569018535 ┆ 56399     ┆ 62336     ┆ 4          ┆ 7       ┆ 0             ┆ 1     │\n",
       "│ 1569018535 ┆ 44790     ┆ 62336     ┆ 4          ┆ 7       ┆ 0             ┆ 1     │\n",
       "│ 1569018535 ┆ 9799      ┆ 62336     ┆ 4          ┆ 7       ┆ 0             ┆ 1     │\n",
       "│ 1569018535 ┆ 16739     ┆ 62336     ┆ 4          ┆ 7       ┆ 0             ┆ 1     │\n",
       "│ 1569024094 ┆ 39645     ┆ 80        ┆ 2          ┆ 5       ┆ 15036790      ┆ 1     │\n",
       "└────────────┴───────────┴───────────┴────────────┴─────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = X.reshape(-1, X.shape[-1])\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape(-1, window_size, X.shape[-1])\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True, dropout=dropout_rate, bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, hidden = self.gru(x)\n",
    "        hidden = self.relu(hidden[-1])\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrain(hidden_dim, dropout_rate, num_epochs):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    start_training = time.time()\n",
    "    results_fold = []\n",
    "    #num_epochs = 10  # Adicionado número de épocas para melhor treinamento\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Normalização correta para evitar vazamento de dados\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(-1, window_size, X_train.shape[-1])\n",
    "        X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(-1, window_size, X_test.shape[-1])\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        input_dim = X_train.shape[2]\n",
    "        #hidden_dim = 100\n",
    "        #dropout_rate = 0.2\n",
    "        output_dim = 1\n",
    "\n",
    "        model = GRUClassifier(input_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        batch_size = 512\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "            #print(f\"Fold {fold}, Época {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_loader.dataset):.4f}\")\n",
    "        \n",
    "        end_training = time.time()\n",
    "\n",
    "        model.eval()\n",
    "        all_outputs, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                all_outputs.append(outputs.cpu())\n",
    "                all_targets.append(targets.cpu())\n",
    "\n",
    "        all_outputs = torch.cat(all_outputs)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "        \n",
    "        y_pred = (all_outputs > 0.5).float().numpy()\n",
    "        y_true = all_targets.numpy()\n",
    "\n",
    "        confusion = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "        false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "        training_duration = end_training - start_training\n",
    "        evaluation_duration = time.time() - end_training\n",
    "        avaliacao = [accuracy, balanced_accuracy, precision, recall, specificity, f1, false_alarm_rate, tn, fp, fn, tp, training_duration, evaluation_duration]\n",
    "        #print(avaliacao)\n",
    "        results_fold.append(avaliacao)\n",
    "\n",
    "    results_fold_array = np.array(results_fold, dtype=np.float32)\n",
    "    mean_results = np.mean(results_fold_array, axis=0)\n",
    "    results.append([\"GRU\"] + mean_results.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melhores Hiperparâmetros encontrados: {'hidden_dim': 100, 'dropout_rate': 0.2, 'num_epochs': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    startTrain(hidden_dim=100,dropout_rate=0.2, num_epochs=10)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Algorithm</th><th>Accuracy</th><th>Balanced Accuracy</th><th>Precision</th><th>Recall</th><th>Specificity</th><th>F1-score</th><th>False Alarm Rate</th><th>tn</th><th>fp</th><th>fn</th><th>tp</th><th>training_duration</th><th>evaluation_duration</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;GRU&quot;</td><td>0.993741</td><td>0.989042</td><td>0.996585</td><td>0.995959</td><td>0.982126</td><td>0.996272</td><td>0.017874</td><td>17484.800781</td><td>318.200012</td><td>376.799988</td><td>92865.796875</td><td>585.624695</td><td>2.811311</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993414</td><td>0.989229</td><td>0.996763</td><td>0.995389</td><td>0.98307</td><td>0.996075</td><td>0.01693</td><td>17501.599609</td><td>301.399994</td><td>430.0</td><td>92812.601562</td><td>583.140991</td><td>2.760882</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993359</td><td>0.988966</td><td>0.996652</td><td>0.995437</td><td>0.982496</td><td>0.996043</td><td>0.017504</td><td>17491.199219</td><td>311.799988</td><td>425.600006</td><td>92817.0</td><td>589.285156</td><td>2.794614</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993669</td><td>0.988993</td><td>0.996581</td><td>0.995878</td><td>0.982108</td><td>0.996229</td><td>0.017892</td><td>17484.400391</td><td>318.600006</td><td>384.399994</td><td>92858.203125</td><td>595.14856</td><td>2.751181</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993386</td><td>0.989265</td><td>0.996786</td><td>0.995333</td><td>0.983196</td><td>0.996059</td><td>0.016804</td><td>17503.800781</td><td>299.200012</td><td>435.200012</td><td>92807.398438</td><td>561.066711</td><td>2.673665</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993642</td><td>0.989261</td><td>0.996715</td><td>0.99571</td><td>0.982812</td><td>0.996212</td><td>0.017188</td><td>17497.0</td><td>306.0</td><td>400.0</td><td>92842.601562</td><td>567.010437</td><td>2.724485</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993491</td><td>0.988892</td><td>0.996582</td><td>0.995663</td><td>0.98212</td><td>0.996122</td><td>0.01788</td><td>17484.599609</td><td>318.399994</td><td>404.399994</td><td>92838.203125</td><td>593.248047</td><td>2.768949</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993403</td><td>0.989378</td><td>0.996836</td><td>0.995303</td><td>0.983454</td><td>0.996068</td><td>0.016546</td><td>17508.400391</td><td>294.600006</td><td>438.0</td><td>92804.601562</td><td>559.894287</td><td>2.682645</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993482</td><td>0.98923</td><td>0.996744</td><td>0.995489</td><td>0.982971</td><td>0.996116</td><td>0.017029</td><td>17499.800781</td><td>303.200012</td><td>420.600006</td><td>92822.0</td><td>515.8396</td><td>2.598066</td></tr><tr><td>&quot;GRU&quot;</td><td>0.993432</td><td>0.989042</td><td>0.996669</td><td>0.995504</td><td>0.98258</td><td>0.996086</td><td>0.01742</td><td>17492.800781</td><td>310.200012</td><td>419.200012</td><td>92823.398438</td><td>572.918091</td><td>2.699635</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 14)\n",
       "┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Algorithm ┆ Accuracy ┆ Balanced  ┆ Precision ┆ … ┆ fn        ┆ tp        ┆ training_ ┆ evaluatio │\n",
       "│ ---       ┆ ---      ┆ Accuracy  ┆ ---       ┆   ┆ ---       ┆ ---       ┆ duration  ┆ n_duratio │\n",
       "│ str       ┆ f64      ┆ ---       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ ---       ┆ n         │\n",
       "│           ┆          ┆ f64       ┆           ┆   ┆           ┆           ┆ f64       ┆ ---       │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64       │\n",
       "╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ GRU       ┆ 0.993741 ┆ 0.989042  ┆ 0.996585  ┆ … ┆ 376.79998 ┆ 92865.796 ┆ 585.62469 ┆ 2.811311  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 8         ┆ 875       ┆ 5         ┆           │\n",
       "│ GRU       ┆ 0.993414 ┆ 0.989229  ┆ 0.996763  ┆ … ┆ 430.0     ┆ 92812.601 ┆ 583.14099 ┆ 2.760882  │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆ 562       ┆ 1         ┆           │\n",
       "│ GRU       ┆ 0.993359 ┆ 0.988966  ┆ 0.996652  ┆ … ┆ 425.60000 ┆ 92817.0   ┆ 589.28515 ┆ 2.794614  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 6         ┆           ┆ 6         ┆           │\n",
       "│ GRU       ┆ 0.993669 ┆ 0.988993  ┆ 0.996581  ┆ … ┆ 384.39999 ┆ 92858.203 ┆ 595.14856 ┆ 2.751181  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 4         ┆ 125       ┆           ┆           │\n",
       "│ GRU       ┆ 0.993386 ┆ 0.989265  ┆ 0.996786  ┆ … ┆ 435.20001 ┆ 92807.398 ┆ 561.06671 ┆ 2.673665  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 2         ┆ 438       ┆ 1         ┆           │\n",
       "│ GRU       ┆ 0.993642 ┆ 0.989261  ┆ 0.996715  ┆ … ┆ 400.0     ┆ 92842.601 ┆ 567.01043 ┆ 2.724485  │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆ 562       ┆ 7         ┆           │\n",
       "│ GRU       ┆ 0.993491 ┆ 0.988892  ┆ 0.996582  ┆ … ┆ 404.39999 ┆ 92838.203 ┆ 593.24804 ┆ 2.768949  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 4         ┆ 125       ┆ 7         ┆           │\n",
       "│ GRU       ┆ 0.993403 ┆ 0.989378  ┆ 0.996836  ┆ … ┆ 438.0     ┆ 92804.601 ┆ 559.89428 ┆ 2.682645  │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆ 562       ┆ 7         ┆           │\n",
       "│ GRU       ┆ 0.993482 ┆ 0.98923   ┆ 0.996744  ┆ … ┆ 420.60000 ┆ 92822.0   ┆ 515.8396  ┆ 2.598066  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 6         ┆           ┆           ┆           │\n",
       "│ GRU       ┆ 0.993432 ┆ 0.989042  ┆ 0.996669  ┆ … ┆ 419.20001 ┆ 92823.398 ┆ 572.91809 ┆ 2.699635  │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 2         ┆ 438       ┆ 1         ┆           │\n",
       "└───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pl.DataFrame(\n",
    "    results,\n",
    "    schema=['Algorithm', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'Specificity', 'F1-score', 'False Alarm Rate', 'tn', 'fp', 'fn', 'tp', 'training_duration', 'evaluation_duration']\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.write_csv(f\"metrics_results/unbalanced_GRU_metrics_output.csv\", separator=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_2025_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
