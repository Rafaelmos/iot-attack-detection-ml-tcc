{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "import ipaddress\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "df_polars_raiz = pl.read_parquet('../dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars_raiz.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_to_int(ip: str) -> int:\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))  # Funciona tanto para IPv4 quanto IPv6\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars = df_polars.with_columns([\n",
    "#    pl.col('id.resp_h').map_elements(ip_to_int).alias('id.resp_h'),\n",
    "#    pl.col('id.orig_h').map_elements(ip_to_int).alias('id.orig_h')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns([\n",
    "    pl.col('duration').fill_null(0),\n",
    "    pl.col('orig_bytes').fill_null(0),\n",
    "    pl.col('resp_bytes').fill_null(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas = df_polars.columns\n",
    "colunas_para_manter = ['ts', 'id.resp_p', 'history', 'conn_state', 'id.orig_p', 'orig_ip_bytes', 'label']  \n",
    "colunas_para_dropar = [col for col in lista_colunas if col not in colunas_para_manter]\n",
    "df_polars = df_polars.drop(colunas_para_dropar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.drop_nulls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (555_233, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>id.orig_p</th><th>proto</th><th>service</th><th>duration</th><th>conn_state</th><th>label</th></tr><tr><td>f64</td><td>i32</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>1.5322e9</td><td>5526</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1.5326e9</td><td>60403</td><td>1</td><td>0</td><td>0.0</td><td>2</td><td>1</td></tr><tr><td>1.5326e9</td><td>13386</td><td>1</td><td>0</td><td>0.0</td><td>2</td><td>1</td></tr><tr><td>1.5455e9</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1.5454e9</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1.5514e9</td><td>30535</td><td>0</td><td>1</td><td>0.000005</td><td>1</td><td>1</td></tr><tr><td>1.5454e9</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1.5514e9</td><td>41258</td><td>0</td><td>1</td><td>0.000002</td><td>1</td><td>1</td></tr><tr><td>1.5514e9</td><td>36658</td><td>0</td><td>1</td><td>0.000214</td><td>1</td><td>1</td></tr><tr><td>1.5454e9</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (555_233, 7)\n",
       "┌──────────┬───────────┬───────┬─────────┬──────────┬────────────┬───────┐\n",
       "│ ts       ┆ id.orig_p ┆ proto ┆ service ┆ duration ┆ conn_state ┆ label │\n",
       "│ ---      ┆ ---       ┆ ---   ┆ ---     ┆ ---      ┆ ---        ┆ ---   │\n",
       "│ f64      ┆ i32       ┆ i64   ┆ i64     ┆ f64      ┆ i64        ┆ i32   │\n",
       "╞══════════╪═══════════╪═══════╪═════════╪══════════╪════════════╪═══════╡\n",
       "│ 1.5322e9 ┆ 5526      ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ 1.5326e9 ┆ 60403     ┆ 1     ┆ 0       ┆ 0.0      ┆ 2          ┆ 1     │\n",
       "│ 1.5326e9 ┆ 13386     ┆ 1     ┆ 0       ┆ 0.0      ┆ 2          ┆ 1     │\n",
       "│ 1.5455e9 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ 1.5454e9 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ …        ┆ …         ┆ …     ┆ …       ┆ …        ┆ …          ┆ …     │\n",
       "│ 1.5514e9 ┆ 30535     ┆ 0     ┆ 1       ┆ 0.000005 ┆ 1          ┆ 1     │\n",
       "│ 1.5454e9 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ 1.5514e9 ┆ 41258     ┆ 0     ┆ 1       ┆ 0.000002 ┆ 1          ┆ 1     │\n",
       "│ 1.5514e9 ┆ 36658     ┆ 0     ┆ 1       ┆ 0.000214 ┆ 1          ┆ 1     │\n",
       "│ 1.5454e9 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "└──────────┴───────────┴───────┴─────────┴──────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns(pl.col(\"ts\").cast(pl.Int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (555_233, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>id.orig_p</th><th>proto</th><th>service</th><th>duration</th><th>conn_state</th><th>label</th></tr><tr><td>i64</td><td>i32</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>1532150893</td><td>5526</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1532570324</td><td>60403</td><td>1</td><td>0</td><td>0.0</td><td>2</td><td>1</td></tr><tr><td>1532564882</td><td>13386</td><td>1</td><td>0</td><td>0.0</td><td>2</td><td>1</td></tr><tr><td>1545465243</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1545398682</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1551404209</td><td>30535</td><td>0</td><td>1</td><td>0.000005</td><td>1</td><td>1</td></tr><tr><td>1545414126</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1551402739</td><td>41258</td><td>0</td><td>1</td><td>0.000002</td><td>1</td><td>1</td></tr><tr><td>1551405886</td><td>36658</td><td>0</td><td>1</td><td>0.000214</td><td>1</td><td>1</td></tr><tr><td>1545405686</td><td>36097</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (555_233, 7)\n",
       "┌────────────┬───────────┬───────┬─────────┬──────────┬────────────┬───────┐\n",
       "│ ts         ┆ id.orig_p ┆ proto ┆ service ┆ duration ┆ conn_state ┆ label │\n",
       "│ ---        ┆ ---       ┆ ---   ┆ ---     ┆ ---      ┆ ---        ┆ ---   │\n",
       "│ i64        ┆ i32       ┆ i64   ┆ i64     ┆ f64      ┆ i64        ┆ i32   │\n",
       "╞════════════╪═══════════╪═══════╪═════════╪══════════╪════════════╪═══════╡\n",
       "│ 1532150893 ┆ 5526      ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ 1532570324 ┆ 60403     ┆ 1     ┆ 0       ┆ 0.0      ┆ 2          ┆ 1     │\n",
       "│ 1532564882 ┆ 13386     ┆ 1     ┆ 0       ┆ 0.0      ┆ 2          ┆ 1     │\n",
       "│ 1545465243 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ 1545398682 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ …          ┆ …         ┆ …     ┆ …       ┆ …        ┆ …          ┆ …     │\n",
       "│ 1551404209 ┆ 30535     ┆ 0     ┆ 1       ┆ 0.000005 ┆ 1          ┆ 1     │\n",
       "│ 1545414126 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "│ 1551402739 ┆ 41258     ┆ 0     ┆ 1       ┆ 0.000002 ┆ 1          ┆ 1     │\n",
       "│ 1551405886 ┆ 36658     ┆ 0     ┆ 1       ┆ 0.000214 ┆ 1          ┆ 1     │\n",
       "│ 1545405686 ┆ 36097     ┆ 0     ┆ 0       ┆ 0.0      ┆ 0          ┆ 1     │\n",
       "└────────────┴───────────┴───────┴─────────┴──────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar apenas pelo campo de tempo \"ts\"\n",
    "df_polars = df_polars.sort(\"ts\")\n",
    "\n",
    "window_size = 5  # Tamanho da janela temporal\n",
    "step_size = 1  # Passo entre janelas\n",
    "\n",
    "def create_sequences(df, window_size, step_size):\n",
    "    sequences, labels = [], []\n",
    "    \n",
    "    # Remover a coluna \"ts\" antes de converter para numpy\n",
    "    group_np = df.drop(\"ts\").to_numpy()\n",
    "    \n",
    "    for i in range(0, len(group_np) - window_size, step_size):\n",
    "        seq = group_np[i:i + window_size, :-1]  # Características\n",
    "        label = group_np[i + window_size - 1, -1]  # Última linha como rótulo\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "\n",
    "# Gerando X e y\n",
    "X, y = create_sequences(df_polars, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (555228, 5, 5)\n",
      "Shape de y: (555228,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape de X:\", X.shape)\n",
    "print(\"Shape de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (555_233, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ts</th><th>id.orig_p</th><th>proto</th><th>service</th><th>duration</th><th>conn_state</th><th>label</th></tr><tr><td>i64</td><td>i32</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>1525879873</td><td>37334</td><td>0</td><td>0</td><td>2.999066</td><td>0</td><td>1</td></tr><tr><td>1525879921</td><td>40983</td><td>0</td><td>0</td><td>2.998808</td><td>0</td><td>0</td></tr><tr><td>1525879944</td><td>46566</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1525879960</td><td>36497</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>1525880010</td><td>40761</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1569018535</td><td>56399</td><td>1</td><td>0</td><td>0.0</td><td>4</td><td>1</td></tr><tr><td>1569018535</td><td>44790</td><td>1</td><td>0</td><td>0.0</td><td>4</td><td>1</td></tr><tr><td>1569018535</td><td>9799</td><td>1</td><td>0</td><td>0.0</td><td>4</td><td>1</td></tr><tr><td>1569018535</td><td>16739</td><td>1</td><td>0</td><td>0.0</td><td>4</td><td>1</td></tr><tr><td>1569024094</td><td>39645</td><td>0</td><td>0</td><td>53.016286</td><td>2</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (555_233, 7)\n",
       "┌────────────┬───────────┬───────┬─────────┬───────────┬────────────┬───────┐\n",
       "│ ts         ┆ id.orig_p ┆ proto ┆ service ┆ duration  ┆ conn_state ┆ label │\n",
       "│ ---        ┆ ---       ┆ ---   ┆ ---     ┆ ---       ┆ ---        ┆ ---   │\n",
       "│ i64        ┆ i32       ┆ i64   ┆ i64     ┆ f64       ┆ i64        ┆ i32   │\n",
       "╞════════════╪═══════════╪═══════╪═════════╪═══════════╪════════════╪═══════╡\n",
       "│ 1525879873 ┆ 37334     ┆ 0     ┆ 0       ┆ 2.999066  ┆ 0          ┆ 1     │\n",
       "│ 1525879921 ┆ 40983     ┆ 0     ┆ 0       ┆ 2.998808  ┆ 0          ┆ 0     │\n",
       "│ 1525879944 ┆ 46566     ┆ 0     ┆ 0       ┆ 0.0       ┆ 0          ┆ 1     │\n",
       "│ 1525879960 ┆ 36497     ┆ 0     ┆ 0       ┆ 0.0       ┆ 0          ┆ 1     │\n",
       "│ 1525880010 ┆ 40761     ┆ 0     ┆ 0       ┆ 0.0       ┆ 0          ┆ 1     │\n",
       "│ …          ┆ …         ┆ …     ┆ …       ┆ …         ┆ …          ┆ …     │\n",
       "│ 1569018535 ┆ 56399     ┆ 1     ┆ 0       ┆ 0.0       ┆ 4          ┆ 1     │\n",
       "│ 1569018535 ┆ 44790     ┆ 1     ┆ 0       ┆ 0.0       ┆ 4          ┆ 1     │\n",
       "│ 1569018535 ┆ 9799      ┆ 1     ┆ 0       ┆ 0.0       ┆ 4          ┆ 1     │\n",
       "│ 1569018535 ┆ 16739     ┆ 1     ┆ 0       ┆ 0.0       ┆ 4          ┆ 1     │\n",
       "│ 1569024094 ┆ 39645     ┆ 0     ┆ 0       ┆ 53.016286 ┆ 2          ┆ 1     │\n",
       "└────────────┴───────────┴───────┴─────────┴───────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = X.reshape(-1, X.shape[-1])\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape(-1, window_size, X.shape[-1])\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True, dropout=dropout_rate, bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, hidden = self.gru(x)\n",
    "        hidden = self.relu(hidden[-1])\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrain(hidden_dim, dropout_rate):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    start_training = time.time()\n",
    "    results_fold = []\n",
    "    num_epochs = 10  # Adicionado número de épocas para melhor treinamento\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Normalização correta para evitar vazamento de dados\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(-1, window_size, X_train.shape[-1])\n",
    "        X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(-1, window_size, X_test.shape[-1])\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        input_dim = X_train.shape[2]\n",
    "        #hidden_dim = 100\n",
    "        #dropout_rate = 0.2\n",
    "        output_dim = 1\n",
    "\n",
    "        model = GRUClassifier(input_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        batch_size = 512\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "            print(f\"Fold {fold}, Época {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_loader.dataset):.4f}\")\n",
    "        \n",
    "        end_training = time.time()\n",
    "\n",
    "        model.eval()\n",
    "        all_outputs, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                all_outputs.append(outputs.cpu())\n",
    "                all_targets.append(targets.cpu())\n",
    "\n",
    "        all_outputs = torch.cat(all_outputs)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "        \n",
    "        y_pred = (all_outputs > 0.5).float().numpy()\n",
    "        y_true = all_targets.numpy()\n",
    "\n",
    "        confusion = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "        false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "        training_duration = end_training - start_training\n",
    "        evaluation_duration = time.time() - end_training\n",
    "        avaliacao = [accuracy, balanced_accuracy, precision, recall, specificity, f1, false_alarm_rate, tn, fp, fn, tp, training_duration, evaluation_duration]\n",
    "        print(avaliacao)\n",
    "        results_fold.append(avaliacao)\n",
    "\n",
    "    results_fold_array = np.array(results_fold, dtype=np.float32)\n",
    "    mean_results = np.mean(results_fold_array, axis=0)\n",
    "    results.append([\"GRU\"] + mean_results.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Época 1/10, Loss: 0.2767\n",
      "Fold 1, Época 2/10, Loss: 0.1786\n",
      "Fold 1, Época 3/10, Loss: 0.1438\n",
      "Fold 1, Época 4/10, Loss: 0.1337\n",
      "Fold 1, Época 5/10, Loss: 0.1293\n",
      "Fold 1, Época 6/10, Loss: 0.1273\n",
      "Fold 1, Época 7/10, Loss: 0.1252\n",
      "Fold 1, Época 8/10, Loss: 0.1244\n",
      "Fold 1, Época 9/10, Loss: 0.1239\n",
      "Fold 1, Época 10/10, Loss: 0.1225\n",
      "[0.9661671739639429, 0.902553816403628, 0.9644671632952031, 0.9963828005924908, 0.8087248322147651, 0.9801652456246865, 0.1912751677852349, 14460, 3420, 337, 92829, 278.4793612957001, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Época 1/10, Loss: 0.2756\n",
      "Fold 2, Época 2/10, Loss: 0.1745\n",
      "Fold 2, Época 3/10, Loss: 0.1442\n",
      "Fold 2, Época 4/10, Loss: 0.1344\n",
      "Fold 2, Época 5/10, Loss: 0.1299\n",
      "Fold 2, Época 6/10, Loss: 0.1275\n",
      "Fold 2, Época 7/10, Loss: 0.1262\n",
      "Fold 2, Época 8/10, Loss: 0.1253\n",
      "Fold 2, Época 9/10, Loss: 0.1245\n",
      "Fold 2, Época 10/10, Loss: 0.1232\n",
      "[0.9665093744934532, 0.902818831375045, 0.964813219434728, 0.9964730601831007, 0.8091646025669894, 0.9803876071193144, 0.1908353974330106, 14374, 3390, 329, 92953, 545.4827289581299, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Época 1/10, Loss: 0.2805\n",
      "Fold 3, Época 2/10, Loss: 0.1847\n",
      "Fold 3, Época 3/10, Loss: 0.1476\n",
      "Fold 3, Época 4/10, Loss: 0.1359\n",
      "Fold 3, Época 5/10, Loss: 0.1302\n",
      "Fold 3, Época 6/10, Loss: 0.1280\n",
      "Fold 3, Época 7/10, Loss: 0.1263\n",
      "Fold 3, Época 8/10, Loss: 0.1249\n",
      "Fold 3, Época 9/10, Loss: 0.1242\n",
      "Fold 3, Época 10/10, Loss: 0.1233\n",
      "[0.9657259153864164, 0.900971330476076, 0.9639798619401049, 0.996394888466862, 0.80554777248529, 0.979919382069897, 0.19445222751471, 14375, 3470, 336, 92865, 806.5596442222595, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Época 1/10, Loss: 0.2744\n",
      "Fold 4, Época 2/10, Loss: 0.1736\n",
      "Fold 4, Época 3/10, Loss: 0.1410\n",
      "Fold 4, Época 4/10, Loss: 0.1319\n",
      "Fold 4, Época 5/10, Loss: 0.1281\n",
      "Fold 4, Época 6/10, Loss: 0.1261\n",
      "Fold 4, Época 7/10, Loss: 0.1244\n",
      "Fold 4, Época 8/10, Loss: 0.1237\n",
      "Fold 4, Época 9/10, Loss: 0.1231\n",
      "Fold 4, Época 10/10, Loss: 0.1225\n",
      "[0.9668692872258994, 0.9037481746656115, 0.9648792953006191, 0.9968020604174491, 0.8106942889137738, 0.9805809356410297, 0.1893057110862262, 14479, 3381, 298, 92887, 1063.179759502411, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Época 1/10, Loss: 0.2773\n",
      "Fold 5, Época 2/10, Loss: 0.1775\n",
      "Fold 5, Época 3/10, Loss: 0.1424\n",
      "Fold 5, Época 4/10, Loss: 0.1336\n",
      "Fold 5, Época 5/10, Loss: 0.1296\n",
      "Fold 5, Época 6/10, Loss: 0.1271\n",
      "Fold 5, Época 7/10, Loss: 0.1256\n",
      "Fold 5, Época 8/10, Loss: 0.1248\n",
      "Fold 5, Época 9/10, Loss: 0.1242\n",
      "Fold 5, Época 10/10, Loss: 0.1233\n",
      "[0.9683011391778108, 0.9087497766337074, 0.9671931703563519, 0.9960911982351492, 0.8214083550322654, 0.9814295059826534, 0.17859164496773464, 14511, 3155, 365, 93014, 1306.3373546600342, 0.0]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Época 1/10, Loss: 0.2790\n",
      "Fold 1, Época 2/10, Loss: 0.1862\n",
      "Fold 1, Época 3/10, Loss: 0.1504\n",
      "Fold 1, Época 4/10, Loss: 0.1383\n",
      "Fold 1, Época 5/10, Loss: 0.1327\n",
      "Fold 1, Época 6/10, Loss: 0.1288\n",
      "Fold 1, Época 7/10, Loss: 0.1269\n",
      "Fold 1, Época 8/10, Loss: 0.1251\n",
      "Fold 1, Época 9/10, Loss: 0.1238\n",
      "Fold 1, Época 10/10, Loss: 0.1227\n",
      "[0.9672658177692127, 0.9073212959802668, 0.9662732925724166, 0.9957387888285426, 0.8189038031319911, 0.9807847842979707, 0.18109619686800896, 14642, 3238, 397, 92769, 225.58472418785095, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Época 1/10, Loss: 0.2788\n",
      "Fold 2, Época 2/10, Loss: 0.1837\n",
      "Fold 2, Época 3/10, Loss: 0.1450\n",
      "Fold 2, Época 4/10, Loss: 0.1345\n",
      "Fold 2, Época 5/10, Loss: 0.1294\n",
      "Fold 2, Época 6/10, Loss: 0.1274\n",
      "Fold 2, Época 7/10, Loss: 0.1253\n",
      "Fold 2, Época 8/10, Loss: 0.1242\n",
      "Fold 2, Época 9/10, Loss: 0.1229\n",
      "Fold 2, Época 10/10, Loss: 0.1224\n",
      "[0.9677791185634782, 0.9068331055638681, 0.9662466995155824, 0.9964516198194722, 0.8172145913082639, 0.9811167405530927, 0.1827854086917361, 14517, 3247, 331, 92951, 456.8099398612976, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Época 1/10, Loss: 0.2753\n",
      "Fold 3, Época 2/10, Loss: 0.1793\n",
      "Fold 3, Época 3/10, Loss: 0.1433\n",
      "Fold 3, Época 4/10, Loss: 0.1328\n",
      "Fold 3, Época 5/10, Loss: 0.1282\n",
      "Fold 3, Época 6/10, Loss: 0.1264\n",
      "Fold 3, Época 7/10, Loss: 0.1252\n",
      "Fold 3, Época 8/10, Loss: 0.1244\n",
      "Fold 3, Época 9/10, Loss: 0.1240\n",
      "Fold 3, Época 10/10, Loss: 0.1232\n",
      "[0.9674729391423375, 0.9061578294093837, 0.9658184540831712, 0.9965129129515777, 0.8158027458671897, 0.9809256247227561, 0.18419725413281032, 14558, 3287, 325, 92876, 670.7493314743042, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Época 1/10, Loss: 0.2744\n",
      "Fold 4, Época 2/10, Loss: 0.1836\n",
      "Fold 4, Época 3/10, Loss: 0.1499\n",
      "Fold 4, Época 4/10, Loss: 0.1375\n",
      "Fold 4, Época 5/10, Loss: 0.1313\n",
      "Fold 4, Época 6/10, Loss: 0.1281\n",
      "Fold 4, Época 7/10, Loss: 0.1264\n",
      "Fold 4, Época 8/10, Loss: 0.1253\n",
      "Fold 4, Época 9/10, Loss: 0.1245\n",
      "Fold 4, Época 10/10, Loss: 0.1234\n",
      "[0.9667342068530775, 0.903305612004585, 0.9647193228436413, 0.9968127917583302, 0.8097984322508399, 0.9805035097904682, 0.19020156774916014, 14463, 3397, 297, 92888, 900.852502822876, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Época 1/10, Loss: 0.2776\n",
      "Fold 5, Época 2/10, Loss: 0.1828\n",
      "Fold 5, Época 3/10, Loss: 0.1474\n",
      "Fold 5, Época 4/10, Loss: 0.1357\n",
      "Fold 5, Época 5/10, Loss: 0.1309\n",
      "Fold 5, Época 6/10, Loss: 0.1272\n",
      "Fold 5, Época 7/10, Loss: 0.1255\n",
      "Fold 5, Época 8/10, Loss: 0.1240\n",
      "Fold 5, Época 9/10, Loss: 0.1230\n",
      "Fold 5, Época 10/10, Loss: 0.1220\n",
      "[0.9679229141339096, 0.9068955480068859, 0.9664897318970801, 0.996401760567151, 0.8173893354466206, 0.9812178351472202, 0.18261066455337938, 14440, 3226, 336, 93043, 1130.0186760425568, 0.0]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Época 1/10, Loss: 0.2801\n",
      "Fold 1, Época 2/10, Loss: 0.1826\n",
      "Fold 1, Época 3/10, Loss: 0.1442\n",
      "Fold 1, Época 4/10, Loss: 0.1333\n",
      "Fold 1, Época 5/10, Loss: 0.1288\n",
      "Fold 1, Época 6/10, Loss: 0.1265\n",
      "Fold 1, Época 7/10, Loss: 0.1248\n",
      "Fold 1, Época 8/10, Loss: 0.1238\n",
      "Fold 1, Época 9/10, Loss: 0.1225\n",
      "Fold 1, Época 10/10, Loss: 0.1217\n",
      "[0.9682924193577437, 0.9092889536230369, 0.9668961781648108, 0.996318399416096, 0.8222595078299776, 0.9813868169395297, 0.17774049217002238, 14702, 3178, 343, 92823, 231.28769636154175, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Época 1/10, Loss: 0.2756\n",
      "Fold 2, Época 2/10, Loss: 0.1827\n",
      "Fold 2, Época 3/10, Loss: 0.1516\n",
      "Fold 2, Época 4/10, Loss: 0.1391\n",
      "Fold 2, Época 5/10, Loss: 0.1336\n",
      "Fold 2, Época 6/10, Loss: 0.1298\n",
      "Fold 2, Época 7/10, Loss: 0.1281\n",
      "Fold 2, Época 8/10, Loss: 0.1270\n",
      "Fold 2, Época 9/10, Loss: 0.1255\n",
      "Fold 2, Época 10/10, Loss: 0.1241\n",
      "[0.9657349206635089, 0.9002159116069183, 0.9638757841256674, 0.996558821637615, 0.8038730015762215, 0.9799448681526615, 0.19612699842377843, 14280, 3484, 321, 92961, 464.3841245174408, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Época 1/10, Loss: 0.2763\n",
      "Fold 3, Época 2/10, Loss: 0.1836\n",
      "Fold 3, Época 3/10, Loss: 0.1476\n",
      "Fold 3, Época 4/10, Loss: 0.1352\n",
      "Fold 3, Época 5/10, Loss: 0.1308\n",
      "Fold 3, Época 6/10, Loss: 0.1281\n",
      "Fold 3, Época 7/10, Loss: 0.1265\n",
      "Fold 3, Época 8/10, Loss: 0.1254\n",
      "Fold 3, Época 9/10, Loss: 0.1245\n",
      "Fold 3, Época 10/10, Loss: 0.1238\n",
      "[0.9648253876771788, 0.8977616477147616, 0.9628074758217495, 0.9965880194418515, 0.7989352759876717, 0.979406554472985, 0.2010647240123284, 14257, 3588, 318, 92883, 704.7466466426849, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Época 1/10, Loss: 0.2795\n",
      "Fold 4, Época 2/10, Loss: 0.1776\n",
      "Fold 4, Época 3/10, Loss: 0.1448\n",
      "Fold 4, Época 4/10, Loss: 0.1341\n",
      "Fold 4, Época 5/10, Loss: 0.1297\n",
      "Fold 4, Época 6/10, Loss: 0.1272\n",
      "Fold 4, Época 7/10, Loss: 0.1256\n",
      "Fold 4, Época 8/10, Loss: 0.1243\n",
      "Fold 4, Época 9/10, Loss: 0.1236\n",
      "Fold 4, Época 10/10, Loss: 0.1228\n",
      "[0.96705839974785, 0.9042003014990049, 0.9650318411784872, 0.9968664484627354, 0.8115341545352743, 0.9806908637908828, 0.18846584546472564, 14494, 3366, 292, 92893, 1379.7719433307648, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Época 1/10, Loss: 0.2788\n",
      "Fold 5, Época 2/10, Loss: 0.1809\n",
      "Fold 5, Época 3/10, Loss: 0.1455\n",
      "Fold 5, Época 4/10, Loss: 0.1348\n",
      "Fold 5, Época 5/10, Loss: 0.1303\n",
      "Fold 5, Época 6/10, Loss: 0.1278\n",
      "Fold 5, Época 7/10, Loss: 0.1260\n",
      "Fold 5, Época 8/10, Loss: 0.1246\n",
      "Fold 5, Época 9/10, Loss: 0.1238\n",
      "Fold 5, Época 10/10, Loss: 0.1231\n",
      "[0.9680039623576028, 0.9071043777366163, 0.9665607080528547, 0.9964231786590133, 0.8177855768142194, 0.9812647975406421, 0.1822144231857806, 14447, 3219, 334, 93045, 1679.4836871623993, 0.0]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Época 1/10, Loss: 0.2776\n",
      "Fold 1, Época 2/10, Loss: 0.1821\n",
      "Fold 1, Época 3/10, Loss: 0.1444\n",
      "Fold 1, Época 4/10, Loss: 0.1333\n",
      "Fold 1, Época 5/10, Loss: 0.1288\n",
      "Fold 1, Época 6/10, Loss: 0.1257\n",
      "Fold 1, Época 7/10, Loss: 0.1247\n",
      "Fold 1, Época 8/10, Loss: 0.1234\n",
      "Fold 1, Época 9/10, Loss: 0.1226\n",
      "Fold 1, Época 10/10, Loss: 0.1215\n",
      "[0.9673108441546746, 0.9064668296002022, 0.9658965553127277, 0.9962110641221046, 0.8167225950782998, 0.9808196305533246, 0.18327740492170022, 14603, 3277, 353, 92813, 402.13818621635437, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Época 1/10, Loss: 0.2747\n",
      "Fold 2, Época 2/10, Loss: 0.1765\n",
      "Fold 2, Época 3/10, Loss: 0.1424\n",
      "Fold 2, Época 4/10, Loss: 0.1327\n",
      "Fold 2, Época 5/10, Loss: 0.1281\n",
      "Fold 2, Época 6/10, Loss: 0.1258\n",
      "Fold 2, Época 7/10, Loss: 0.1248\n",
      "Fold 2, Época 8/10, Loss: 0.1237\n",
      "Fold 2, Época 9/10, Loss: 0.1234\n",
      "Fold 2, Época 10/10, Loss: 0.1225\n",
      "[0.9684815301766836, 0.9095982251105995, 0.9672738628083689, 0.996183615274115, 0.823012834947084, 0.9815159068824201, 0.176987165052916, 14620, 3144, 356, 92926, 772.7072694301605, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Época 1/10, Loss: 0.2762\n",
      "Fold 3, Época 2/10, Loss: 0.1753\n",
      "Fold 3, Época 3/10, Loss: 0.1410\n",
      "Fold 3, Época 4/10, Loss: 0.1324\n",
      "Fold 3, Época 5/10, Loss: 0.1287\n",
      "Fold 3, Época 6/10, Loss: 0.1268\n",
      "Fold 3, Época 7/10, Loss: 0.1254\n",
      "Fold 3, Época 8/10, Loss: 0.1247\n",
      "Fold 3, Época 9/10, Loss: 0.1232\n",
      "Fold 3, Época 10/10, Loss: 0.1225\n",
      "[0.9673738810943213, 0.9059175827378199, 0.9657370435071957, 0.9964807244557462, 0.8153544410198935, 0.9808680407035999, 0.18464555898010648, 14550, 3295, 328, 92873, 1122.2704317569733, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Época 1/10, Loss: 0.2789\n",
      "Fold 4, Época 2/10, Loss: 0.1808\n",
      "Fold 4, Época 3/10, Loss: 0.1443\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    startTrain(hidden_dim=200,dropout_rate=0.2)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Algorithm</th><th>Accuracy</th><th>Balanced Accuracy</th><th>Precision</th><th>Recall</th><th>Specificity</th><th>F1-score</th><th>False Alarm Rate</th><th>tn</th><th>fp</th><th>fn</th><th>tp</th><th>training_duration</th><th>evaluation_duration</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;GRU&quot;</td><td>0.957686</td><td>0.921282</td><td>0.965695</td><td>0.982009</td><td>0.860556</td><td>0.973755</td><td>0.139444</td><td>52190.199219</td><td>8455.200195</td><td>4355.200195</td><td>237743.796875</td><td>172.253525</td><td>0.0</td></tr><tr><td>&quot;GRU&quot;</td><td>0.956743</td><td>0.918005</td><td>0.964073</td><td>0.982616</td><td>0.853393</td><td>0.973159</td><td>0.146607</td><td>51756.601562</td><td>8888.799805</td><td>4207.0</td><td>237892.0</td><td>181.652786</td><td>0.0</td></tr><tr><td>&quot;GRU&quot;</td><td>0.952793</td><td>0.921479</td><td>0.967498</td><td>0.973738</td><td>0.869221</td><td>0.970536</td><td>0.130779</td><td>52713.0</td><td>7932.399902</td><td>6359.399902</td><td>235739.59375</td><td>203.197937</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 14)\n",
       "┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Algorithm ┆ Accuracy ┆ Balanced  ┆ Precision ┆ … ┆ fn        ┆ tp        ┆ training_ ┆ evaluatio │\n",
       "│ ---       ┆ ---      ┆ Accuracy  ┆ ---       ┆   ┆ ---       ┆ ---       ┆ duration  ┆ n_duratio │\n",
       "│ str       ┆ f64      ┆ ---       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ ---       ┆ n         │\n",
       "│           ┆          ┆ f64       ┆           ┆   ┆           ┆           ┆ f64       ┆ ---       │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64       │\n",
       "╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ GRU       ┆ 0.957686 ┆ 0.921282  ┆ 0.965695  ┆ … ┆ 4355.2001 ┆ 237743.79 ┆ 172.25352 ┆ 0.0       │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 95        ┆ 6875      ┆ 5         ┆           │\n",
       "│ GRU       ┆ 0.956743 ┆ 0.918005  ┆ 0.964073  ┆ … ┆ 4207.0    ┆ 237892.0  ┆ 181.65278 ┆ 0.0       │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆           ┆ 6         ┆           │\n",
       "│ GRU       ┆ 0.952793 ┆ 0.921479  ┆ 0.967498  ┆ … ┆ 6359.3999 ┆ 235739.59 ┆ 203.19793 ┆ 0.0       │\n",
       "│           ┆          ┆           ┆           ┆   ┆ 02        ┆ 375       ┆ 7         ┆           │\n",
       "└───────────┴──────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pl.DataFrame(\n",
    "    results,\n",
    "    schema=['Algorithm', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'Specificity', 'F1-score', 'False Alarm Rate', 'tn', 'fp', 'fn', 'tp', 'training_duration', 'evaluation_duration']\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.write_csv(f\"metrics_results/unbalanced_GRU_metrics_output.csv\", separator=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_2025_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
