{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = pl.read_parquet('dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "def ip_to_int(ip: str) -> int:\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))  # Funciona tanto para IPv4 quanto IPv6\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars = df_polars.with_columns([\n",
    "#    pl.col('id.resp_h').map_elements(ip_to_int).alias('id.resp_h'),\n",
    "#    pl.col('id.orig_h').map_elements(ip_to_int).alias('id.orig_h')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns([\n",
    "    pl.col('duration').fill_null(0),\n",
    "    pl.col('orig_bytes').fill_null(0),\n",
    "    pl.col('resp_bytes').fill_null(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas = df_polars.columns\n",
    "colunas_para_spearman = ['id.resp_p', 'history', 'id.orig_h', 'conn_state', 'id.orig_p', 'orig_ip_bytes', 'label']\n",
    "#['detailed-label', 'id.resp_p', 'history', 'id.orig_h', 'conn_state', 'id.orig_p', 'orig_ip_bytes']\n",
    "colunas_para_dropar = [col for col in lista_colunas if col not in colunas_para_spearman]\n",
    "df_polars = df_polars.drop(colunas_para_dropar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_polars.drop('label')\n",
    "y = df_polars['label']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "X[:, 0] = np.array([ip_to_int(ip) for ip in X[:, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 8),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrain():\n",
    "    # Divisão dos dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    # Converter para arrays numpy se necessário\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Filtrar dados benignos (classe 0) para treinar o Autoencoder\n",
    "    X_train = X_train[y_train == 0]\n",
    "\n",
    "    # Converter os dados para tensores PyTorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Criar DataLoaders\n",
    "    batch_size = 5000\n",
    "    train_dataset = TensorDataset(X_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Configuração do dispositivo e modelo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = Autoencoder(input_dim).to(device)\n",
    "\n",
    "    # Definição da função de perda e otimizador\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Treinamento\n",
    "    epochs = 25\n",
    "    start_training = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs = data[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    end_training = time.time()\n",
    "\n",
    "    # Avaliação do limiar baseado no conjunto de treino\n",
    "    model.eval()\n",
    "    reconstruction_errors_train = []\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            inputs = data[0].to(device)\n",
    "            outputs = model(inputs)\n",
    "            reconstruction_error = torch.mean((outputs - inputs) ** 2, dim=1)\n",
    "            reconstruction_errors_train.extend(reconstruction_error.cpu().numpy())\n",
    "\n",
    "    reconstruction_errors_train = np.array(reconstruction_errors_train)\n",
    "    threshold = np.percentile(reconstruction_errors_train, 95)  # Limiar baseado no percentil 95\n",
    "\n",
    "    # Avaliação no conjunto de teste\n",
    "    reconstruction_errors_test = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data[0].to(device), data[1].cpu().numpy()\n",
    "            outputs = model(inputs)\n",
    "            reconstruction_error = torch.mean((outputs - inputs) ** 2, dim=1).cpu().numpy()\n",
    "            reconstruction_errors_test.extend(reconstruction_error)\n",
    "            y_pred.extend((reconstruction_error > threshold).astype(int))\n",
    "\n",
    "    # Conversão para numpy arrays\n",
    "    reconstruction_errors_test = np.array(reconstruction_errors_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Cálculo de métricas de desempenho\n",
    "    evaluation_time = time.time()\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    training_duration = end_training - start_training\n",
    "    evaluation_duration = evaluation_time - end_training\n",
    "\n",
    "    # Registro dos resultados\n",
    "    results.append([\n",
    "        \"AE\", accuracy, balanced_accuracy, precision, recall, specificity, f1, \n",
    "        false_alarm_rate, tn, fp, fn, tp, training_duration, evaluation_duration\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    startTrain()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (30, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Algorithm</th><th>Accuracy</th><th>Balanced Accuracy</th><th>Precision</th><th>Recall</th><th>Specificity</th><th>F1-score</th><th>False Alarm Rate</th><th>tn</th><th>fp</th><th>fn</th><th>tp</th><th>training_duration</th><th>evaluation_duration</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;AE&quot;</td><td>0.980831</td><td>0.968453</td><td>0.990461</td><td>0.986673</td><td>0.950234</td><td>0.988564</td><td>0.049766</td><td>25376</td><td>1329</td><td>1864</td><td>138001</td><td>16.863118</td><td>3.077693</td></tr><tr><td>&quot;AE&quot;</td><td>0.98301</td><td>0.969372</td><td>0.990311</td><td>0.989447</td><td>0.949298</td><td>0.989879</td><td>0.050702</td><td>25351</td><td>1354</td><td>1476</td><td>138389</td><td>15.318</td><td>3.089932</td></tr><tr><td>&quot;AE&quot;</td><td>0.733632</td><td>0.820936</td><td>0.986252</td><td>0.692425</td><td>0.949448</td><td>0.813623</td><td>0.050552</td><td>25355</td><td>1350</td><td>43019</td><td>96846</td><td>15.180101</td><td>3.386056</td></tr><tr><td>&quot;AE&quot;</td><td>0.979732</td><td>0.968011</td><td>0.990548</td><td>0.985264</td><td>0.950758</td><td>0.987899</td><td>0.049242</td><td>25390</td><td>1315</td><td>2061</td><td>137804</td><td>15.262564</td><td>2.784892</td></tr><tr><td>&quot;AE&quot;</td><td>0.97993</td><td>0.967569</td><td>0.990289</td><td>0.985765</td><td>0.949373</td><td>0.988022</td><td>0.050627</td><td>25353</td><td>1352</td><td>1991</td><td>137874</td><td>14.001396</td><td>2.788628</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;AE&quot;</td><td>0.984889</td><td>0.971552</td><td>0.990823</td><td>0.991184</td><td>0.951919</td><td>0.991004</td><td>0.048081</td><td>25421</td><td>1284</td><td>1233</td><td>138632</td><td>14.089062</td><td>2.972274</td></tr><tr><td>&quot;AE&quot;</td><td>0.982902</td><td>0.969369</td><td>0.990338</td><td>0.98929</td><td>0.949448</td><td>0.989813</td><td>0.050552</td><td>25355</td><td>1350</td><td>1498</td><td>138367</td><td>14.833154</td><td>2.841163</td></tr><tr><td>&quot;AE&quot;</td><td>0.982536</td><td>0.969423</td><td>0.99046</td><td>0.988725</td><td>0.950122</td><td>0.989592</td><td>0.049878</td><td>25373</td><td>1332</td><td>1577</td><td>138288</td><td>14.06091</td><td>2.862068</td></tr><tr><td>&quot;AE&quot;</td><td>0.982044</td><td>0.968827</td><td>0.990314</td><td>0.988282</td><td>0.949373</td><td>0.989297</td><td>0.050627</td><td>25353</td><td>1352</td><td>1639</td><td>138226</td><td>14.509449</td><td>2.988646</td></tr><tr><td>&quot;AE&quot;</td><td>0.983508</td><td>0.970745</td><td>0.990815</td><td>0.989533</td><td>0.951957</td><td>0.990173</td><td>0.048043</td><td>25422</td><td>1283</td><td>1464</td><td>138401</td><td>14.459036</td><td>2.873011</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (30, 14)\n",
       "┌───────────┬──────────┬──────────┬───────────┬───┬───────┬────────┬───────────────┬───────────────┐\n",
       "│ Algorithm ┆ Accuracy ┆ Balanced ┆ Precision ┆ … ┆ fn    ┆ tp     ┆ training_dura ┆ evaluation_du │\n",
       "│ ---       ┆ ---      ┆ Accuracy ┆ ---       ┆   ┆ ---   ┆ ---    ┆ tion          ┆ ration        │\n",
       "│ str       ┆ f64      ┆ ---      ┆ f64       ┆   ┆ i64   ┆ i64    ┆ ---           ┆ ---           │\n",
       "│           ┆          ┆ f64      ┆           ┆   ┆       ┆        ┆ f64           ┆ f64           │\n",
       "╞═══════════╪══════════╪══════════╪═══════════╪═══╪═══════╪════════╪═══════════════╪═══════════════╡\n",
       "│ AE        ┆ 0.980831 ┆ 0.968453 ┆ 0.990461  ┆ … ┆ 1864  ┆ 138001 ┆ 16.863118     ┆ 3.077693      │\n",
       "│ AE        ┆ 0.98301  ┆ 0.969372 ┆ 0.990311  ┆ … ┆ 1476  ┆ 138389 ┆ 15.318        ┆ 3.089932      │\n",
       "│ AE        ┆ 0.733632 ┆ 0.820936 ┆ 0.986252  ┆ … ┆ 43019 ┆ 96846  ┆ 15.180101     ┆ 3.386056      │\n",
       "│ AE        ┆ 0.979732 ┆ 0.968011 ┆ 0.990548  ┆ … ┆ 2061  ┆ 137804 ┆ 15.262564     ┆ 2.784892      │\n",
       "│ AE        ┆ 0.97993  ┆ 0.967569 ┆ 0.990289  ┆ … ┆ 1991  ┆ 137874 ┆ 14.001396     ┆ 2.788628      │\n",
       "│ …         ┆ …        ┆ …        ┆ …         ┆ … ┆ …     ┆ …      ┆ …             ┆ …             │\n",
       "│ AE        ┆ 0.984889 ┆ 0.971552 ┆ 0.990823  ┆ … ┆ 1233  ┆ 138632 ┆ 14.089062     ┆ 2.972274      │\n",
       "│ AE        ┆ 0.982902 ┆ 0.969369 ┆ 0.990338  ┆ … ┆ 1498  ┆ 138367 ┆ 14.833154     ┆ 2.841163      │\n",
       "│ AE        ┆ 0.982536 ┆ 0.969423 ┆ 0.99046   ┆ … ┆ 1577  ┆ 138288 ┆ 14.06091      ┆ 2.862068      │\n",
       "│ AE        ┆ 0.982044 ┆ 0.968827 ┆ 0.990314  ┆ … ┆ 1639  ┆ 138226 ┆ 14.509449     ┆ 2.988646      │\n",
       "│ AE        ┆ 0.983508 ┆ 0.970745 ┆ 0.990815  ┆ … ┆ 1464  ┆ 138401 ┆ 14.459036     ┆ 2.873011      │\n",
       "└───────────┴──────────┴──────────┴───────────┴───┴───────┴────────┴───────────────┴───────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pl.DataFrame(\n",
    "    results,\n",
    "    schema=['Algorithm', 'Accuracy', 'Balanced Accuracy' , 'Precision', 'Recall', 'Specificity', 'F1-score', 'False Alarm Rate', 'tn', 'fp', 'fn', 'tp', 'training_duration', 'evaluation_duration']\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.write_csv(f\"metrics_results/unbalanced_AE_metrics_output.csv\", separator=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_2025_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
