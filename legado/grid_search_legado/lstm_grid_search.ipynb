{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = pl.read_parquet('dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "def ip_to_int(ip: str) -> int:\n",
    "    try:\n",
    "        return int(ipaddress.ip_address(ip))  # Funciona tanto para IPv4 quanto IPv6\n",
    "    except ValueError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars = df_polars.with_columns([\n",
    "#    pl.col('id.resp_h').map_elements(ip_to_int).alias('id.resp_h'),\n",
    "#    pl.col('id.orig_h').map_elements(ip_to_int).alias('id.orig_h')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns([\n",
    "    pl.col('duration').fill_null(0),\n",
    "    pl.col('orig_bytes').fill_null(0),\n",
    "    pl.col('resp_bytes').fill_null(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas = df_polars.columns\n",
    "colunas_para_spearman = ['id.resp_p', 'history', 'id.orig_h', 'conn_state', 'id.orig_p', 'orig_ip_bytes', 'label']\n",
    "#['detailed-label', 'id.resp_p', 'history', 'id.orig_h', 'conn_state', 'id.orig_p', 'orig_ip_bytes']\n",
    "colunas_para_dropar = [col for col in lista_colunas if col not in colunas_para_spearman]\n",
    "df_polars = df_polars.drop(colunas_para_dropar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_polars.drop('label')\n",
    "y = df_polars['label']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "X[:, 0] = np.array([ip_to_int(ip) for ip in X[:, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout_rate, bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, (hidden, _) = self.lstm(x)\n",
    "        hidden = self.relu(hidden[-1])\n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.fc(hidden)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTrain():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    y_train_np = y_train.to_numpy()\n",
    "    y_test_np = y_test.to_numpy()\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    input_dim = X_train.shape[1]  \n",
    "    hidden_dim = 100  \n",
    "    dropout_rate = 0.2  \n",
    "    output_dim = 1  \n",
    "\n",
    "    model = LSTMClassifier(input_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "\n",
    "    batch_size = 5000\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    epochs = 10\n",
    "    #print(datetime.now)\n",
    "    start_training = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "            inputs = inputs.unsqueeze(1) \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "        end_training = time.time()\n",
    "        #print(f'Epoch {epoch+1}/{epochs}, fim em: {datetime.now()}')\n",
    "    \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            all_outputs = []\n",
    "            all_targets = []\n",
    "            for data in test_loader:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "                inputs = inputs.unsqueeze(1)  \n",
    "                outputs = model(inputs)\n",
    "                all_outputs.append(outputs.cpu())\n",
    "                all_targets.append(targets.cpu())\n",
    "            \n",
    "        all_outputs = torch.cat(all_outputs)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        y_pred = (all_outputs > 0.5).float().numpy()\n",
    "        y_true = all_targets.numpy()\n",
    "        evaluation_time = time.time()\n",
    "        #print(f'Epoch {epoch+1}/{epochs}, avaliada em: {datetime.now()}')\n",
    "\n",
    "    training_duration = end_training - start_training\n",
    "    evaluation_duration = evaluation_time - end_training\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "    #results.append([epoch+1, accuracy, balanced_accuracy, precision, recall, specificity, f1, false_alarm_rate, tn, fp, fn, tp])\n",
    "    results.append([\"LSTM\", accuracy, balanced_accuracy, precision, recall, specificity, f1, false_alarm_rate, tn, fp, fn, tp, training_duration, evaluation_duration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    startTrain()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\anaconda3\\envs\\tcc_2025_py39\\lib\\functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (30, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Algorithm</th><th>Accuracy</th><th>Balanced Accuracy</th><th>Precision</th><th>Recall</th><th>Specificity</th><th>F1-score</th><th>False Alarm Rate</th><th>tn</th><th>fp</th><th>fn</th><th>tp</th><th>training_duration</th><th>evaluation_duration</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;LSTM&quot;</td><td>0.955592</td><td>0.951546</td><td>0.989267</td><td>0.957502</td><td>0.945591</td><td>0.973125</td><td>0.054409</td><td>25252</td><td>1453</td><td>5944</td><td>133921</td><td>87.819078</td><td>2.644053</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.956265</td><td>0.950492</td><td>0.988583</td><td>0.958989</td><td>0.941996</td><td>0.973561</td><td>0.058004</td><td>25156</td><td>1549</td><td>5736</td><td>134129</td><td>92.902134</td><td>2.84773</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.957399</td><td>0.953425</td><td>0.989673</td><td>0.959275</td><td>0.947575</td><td>0.974237</td><td>0.052425</td><td>25305</td><td>1400</td><td>5696</td><td>134169</td><td>96.294487</td><td>2.118462</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.958624</td><td>0.953124</td><td>0.989199</td><td>0.96122</td><td>0.945029</td><td>0.975009</td><td>0.054971</td><td>25237</td><td>1468</td><td>5424</td><td>134441</td><td>88.887273</td><td>2.442634</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.959573</td><td>0.95431</td><td>0.989506</td><td>0.962056</td><td>0.946564</td><td>0.975588</td><td>0.053436</td><td>25278</td><td>1427</td><td>5307</td><td>134558</td><td>94.43725</td><td>2.685967</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.95776</td><td>0.952367</td><td>0.989072</td><td>0.960305</td><td>0.94443</td><td>0.974476</td><td>0.05557</td><td>25221</td><td>1484</td><td>5552</td><td>134313</td><td>75.999855</td><td>2.068467</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.957177</td><td>0.951839</td><td>0.988978</td><td>0.959697</td><td>0.943981</td><td>0.974117</td><td>0.056019</td><td>25209</td><td>1496</td><td>5637</td><td>134228</td><td>82.167194</td><td>2.382336</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.958966</td><td>0.953404</td><td>0.989239</td><td>0.961592</td><td>0.945216</td><td>0.975219</td><td>0.054784</td><td>25242</td><td>1463</td><td>5372</td><td>134493</td><td>98.986039</td><td>2.834619</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.955784</td><td>0.950403</td><td>0.98867</td><td>0.958324</td><td>0.942483</td><td>0.973261</td><td>0.057517</td><td>25169</td><td>1536</td><td>5829</td><td>134036</td><td>83.377934</td><td>2.162591</td></tr><tr><td>&quot;LSTM&quot;</td><td>0.962424</td><td>0.95613</td><td>0.9896</td><td>0.965395</td><td>0.946864</td><td>0.977348</td><td>0.053136</td><td>25286</td><td>1419</td><td>4840</td><td>135025</td><td>79.442427</td><td>2.057916</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (30, 14)\n",
       "┌───────────┬──────────┬──────────┬───────────┬───┬──────┬────────┬────────────────┬───────────────┐\n",
       "│ Algorithm ┆ Accuracy ┆ Balanced ┆ Precision ┆ … ┆ fn   ┆ tp     ┆ training_durat ┆ evaluation_du │\n",
       "│ ---       ┆ ---      ┆ Accuracy ┆ ---       ┆   ┆ ---  ┆ ---    ┆ ion            ┆ ration        │\n",
       "│ str       ┆ f64      ┆ ---      ┆ f64       ┆   ┆ i64  ┆ i64    ┆ ---            ┆ ---           │\n",
       "│           ┆          ┆ f64      ┆           ┆   ┆      ┆        ┆ f64            ┆ f64           │\n",
       "╞═══════════╪══════════╪══════════╪═══════════╪═══╪══════╪════════╪════════════════╪═══════════════╡\n",
       "│ LSTM      ┆ 0.955592 ┆ 0.951546 ┆ 0.989267  ┆ … ┆ 5944 ┆ 133921 ┆ 87.819078      ┆ 2.644053      │\n",
       "│ LSTM      ┆ 0.956265 ┆ 0.950492 ┆ 0.988583  ┆ … ┆ 5736 ┆ 134129 ┆ 92.902134      ┆ 2.84773       │\n",
       "│ LSTM      ┆ 0.957399 ┆ 0.953425 ┆ 0.989673  ┆ … ┆ 5696 ┆ 134169 ┆ 96.294487      ┆ 2.118462      │\n",
       "│ LSTM      ┆ 0.958624 ┆ 0.953124 ┆ 0.989199  ┆ … ┆ 5424 ┆ 134441 ┆ 88.887273      ┆ 2.442634      │\n",
       "│ LSTM      ┆ 0.959573 ┆ 0.95431  ┆ 0.989506  ┆ … ┆ 5307 ┆ 134558 ┆ 94.43725       ┆ 2.685967      │\n",
       "│ …         ┆ …        ┆ …        ┆ …         ┆ … ┆ …    ┆ …      ┆ …              ┆ …             │\n",
       "│ LSTM      ┆ 0.95776  ┆ 0.952367 ┆ 0.989072  ┆ … ┆ 5552 ┆ 134313 ┆ 75.999855      ┆ 2.068467      │\n",
       "│ LSTM      ┆ 0.957177 ┆ 0.951839 ┆ 0.988978  ┆ … ┆ 5637 ┆ 134228 ┆ 82.167194      ┆ 2.382336      │\n",
       "│ LSTM      ┆ 0.958966 ┆ 0.953404 ┆ 0.989239  ┆ … ┆ 5372 ┆ 134493 ┆ 98.986039      ┆ 2.834619      │\n",
       "│ LSTM      ┆ 0.955784 ┆ 0.950403 ┆ 0.98867   ┆ … ┆ 5829 ┆ 134036 ┆ 83.377934      ┆ 2.162591      │\n",
       "│ LSTM      ┆ 0.962424 ┆ 0.95613  ┆ 0.9896    ┆ … ┆ 4840 ┆ 135025 ┆ 79.442427      ┆ 2.057916      │\n",
       "└───────────┴──────────┴──────────┴───────────┴───┴──────┴────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pl.DataFrame(\n",
    "    results,\n",
    "    schema=['Algorithm', 'Accuracy', 'Balanced Accuracy' , 'Precision', 'Recall', 'Specificity', 'F1-score', 'False Alarm Rate', 'tn', 'fp', 'fn', 'tp', 'training_duration', 'evaluation_duration']\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.write_csv(f\"metrics_results/unbalanced_LSTM_metrics_output.csv\", separator=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_2025_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
